{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ3DayKYD-aF"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow numpy matplotlib datasets arabic_reshaper python_bidi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "id": "YtyJxNJuEFlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from   warnings                             import filterwarnings; filterwarnings(\"ignore\")\n",
        "from   io                                   import BytesIO\n",
        "import re\n",
        "from   datasets                             import load_dataset\n",
        "from   PIL                                  import Image\n",
        "from   arabic_reshaper                      import arabic_reshaper\n",
        "from   bidi.algorithm                       import get_display\n",
        "from   tensorflow.keras.applications.resnet import preprocess_input\n",
        "from   tensorflow.keras.callbacks           import Callback\n",
        "from   tensorflow.keras.backend             import ctc_decode\n",
        "from   tensorflow.keras.layers              import StringLookup\n",
        "\n",
        "import keras\n",
        "import tensorflow        as tf\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt; plt.rcParams[\"font.family\"] = \"DejaVu Sans\""
      ],
      "metadata": {
        "id": "9-m8R9q6EGq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Experiments"
      ],
      "metadata": {
        "id": "2MQPYeMlrSn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load the data"
      ],
      "metadata": {
        "id": "kavMpiRBrTdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mssqpi/Arabic-OCR-Dataset\")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "kDzMcpvGF3-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train      = dataset[\"train\"].select(range(50000))\n",
        "validation = dataset[\"train\"].select(range(50000,51000))\n",
        "test       = dataset[\"train\"].select(range(51000,52000))"
      ],
      "metadata": {
        "id": "JYjv1ETw0EnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocess the data"
      ],
      "metadata": {
        "id": "-H3YkcLUrW3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_with_padding(img, target_size):\n",
        "    target_width  , target_height   = target_size\n",
        "    original_width, original_height = img.size\n",
        "\n",
        "    ratio    = min(target_width / original_width, target_height / original_height)\n",
        "    new_size = (int(original_width * ratio), int(original_height * ratio))\n",
        "    resized  = img.resize(new_size, Image.Resampling.LANCZOS)\n",
        "\n",
        "    padded_img     = Image.new(\"RGB\", (target_width, target_height), (255, 255, 255))\n",
        "    paste_position = ((target_width - new_size[0]) // 2, (target_height - new_size[1]) // 2)\n",
        "    padded_img.paste(resized, paste_position)\n",
        "\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def preprocess(target_size=(80, 35),normalize=True):\n",
        "    def process_split(split):\n",
        "        images = []\n",
        "        texts  = []\n",
        "\n",
        "        for sample in split:\n",
        "            img = sample[\"image\"]\n",
        "\n",
        "            if isinstance(img, dict) and \"bytes\" in img: img = Image.open(BytesIO(img[\"bytes\"]))\n",
        "\n",
        "            resized_img = resize_with_padding(img, target_size)\n",
        "\n",
        "            images.append(np.array(resized_img))\n",
        "            texts .append(sample[\"text\"])\n",
        "\n",
        "        if normalize: return np.array(images), np.array(texts)\n",
        "\n",
        "        return np.array(images), np.array(texts)\n",
        "\n",
        "    train_images     , train_texts      = process_split(train)\n",
        "    validation_images, validation_texts = process_split(validation)\n",
        "    test_images      , test_texts       = process_split(test)\n",
        "\n",
        "    return (train_images, train_texts), (validation_images, validation_texts), (test_images, test_texts)"
      ],
      "metadata": {
        "id": "LCMl51R70IaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_texts),(validation_images,validation_texts),(test_images,test_texts) = preprocess()"
      ],
      "metadata": {
        "id": "ZSK0hhZaF4t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train image shape:\", train_images.shape)"
      ],
      "metadata": {
        "id": "GDWyTwtzF6mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list     = []\n",
        "all_text = np.concatenate((train_texts,validation_texts,test_texts))\n",
        "\n",
        "\n",
        "for text in all_text:\n",
        "    if not text: continue\n",
        "\n",
        "    temp = [ord(char) for char in text]\n",
        "\n",
        "    list.append(temp)\n",
        "\n",
        "number_set = set()\n",
        "\n",
        "for numbers in list:\n",
        "    for number in numbers:\n",
        "        number_set.add(number)\n",
        "\n",
        "print(f\"Number char in the data {len(number_set)}\")"
      ],
      "metadata": {
        "id": "a3yurEYMGGC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_text = 0\n",
        "\n",
        "for text in all_text: max_text = max(max_text, len(text))\n",
        "\n",
        "print(f\"Max text length {max_text}\")"
      ],
      "metadata": {
        "id": "i3_bJFK7GR9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = np.concatenate((train_texts,validation_texts,test_texts))\n",
        "char_set = set()\n",
        "\n",
        "for text in all_text:\n",
        "    if not text: continue\n",
        "\n",
        "    chars = [char for char in text]\n",
        "\n",
        "    for char in chars: char_set.add(char)\n",
        "\n",
        "char_set = sorted(char_set)\n",
        "\n",
        "print(f\"The char in vocab {char_set}\")"
      ],
      "metadata": {
        "id": "yElC8_LSHAXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a string lookup for convert the string to numbers"
      ],
      "metadata": {
        "id": "BKKs0wQTrf5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = StringLookup(vocabulary=char_set,  mask_token=None )\n",
        "\n",
        "num_to_char = StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)"
      ],
      "metadata": {
        "id": "i44xvrN0kNI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The vocabulary is {char_to_num.get_vocabulary()}\")"
      ],
      "metadata": {
        "id": "dIi6FW0ukOg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the image to be suitable for ResNet152"
      ],
      "metadata": {
        "id": "ZFEKiCVwrj4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images      = preprocess_input(train_images)\n",
        "validation_images = preprocess_input(validation_images)\n",
        "test_images       = preprocess_input(test_images)"
      ],
      "metadata": {
        "id": "ICzC4prnkU-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the data to tenserflow dataset"
      ],
      "metadata": {
        "id": "LrjHyMRer2yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(image, label):\n",
        "    img   = tf.convert_to_tensor(image)\n",
        "\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "\n",
        "    return {\"image\": img, \"label\": label}"
      ],
      "metadata": {
        "id": "Ugf3S6VlkZ-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(images,texts,padded_batch=16):\n",
        "    data = tf.data.Dataset.from_tensor_slices((images, texts))\n",
        "\n",
        "    data = (data.map(encode_data, num_parallel_calls=tf.data.AUTOTUNE).padded_batch(padded_batch).prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "Ij8LOwsGkbY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset      = prepare_dataset(train_images, train_texts,4)\n",
        "validation_dataset = prepare_dataset(validation_images, validation_texts,4)\n",
        "test_dataset       = prepare_dataset(test_images, test_texts,4)"
      ],
      "metadata": {
        "id": "cJGyeZuCkc2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation ctc layer\n",
        "This is a custom Keras layer that implements the Connectionist Temporal Classification (CTC) loss function, commonly used for sequence learning tasks like speech recognition or handwriting recognition."
      ],
      "metadata": {
        "id": "V-_cWPRDr63g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCLayer(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_len    = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss         = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "Q6pEOPJkkix7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model use ResNet152 base model"
      ],
      "metadata": {
        "id": "p1BSlZPdr_fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    base_model = tf.keras.applications.ResNet152(weights=\"imagenet\", include_top=False, input_shape=(35,80,3))\n",
        "    imgs       = tf.keras.layers.Input(shape=(35, 80, 3), name=\"image\", dtype=\"float32\")\n",
        "    labels     = tf.keras.layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "    x          = base_model(imgs, training=False)\n",
        "    x          = keras.layers.Resizing(15, 20)(x)\n",
        "    new_shape  = (x.shape[2], x.shape[1] * x.shape[3])\n",
        "\n",
        "    x          = tf.keras.layers.Reshape(new_shape, name=\"reshape\")(x)\n",
        "    x          = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x          = tf.keras.layers.BatchNormalization(name=\"BatchNormalization3\")(x)\n",
        "    x          = tf.keras.layers.Dropout(0.5, name=\"dropout1\")(x)\n",
        "\n",
        "    x          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True))(x)\n",
        "    x          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True))(x)\n",
        "    x          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
        "    x          = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "\n",
        "    x          = tf.keras.layers.Dense(len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\",name=\"dense2\")(x)\n",
        "\n",
        "    output     = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "    model      = tf.keras.models.Model(inputs=[imgs, labels], outputs=output)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,clipvalue=1.0))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "t0MmVlGGkkRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mbSeItd0NcU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a edit distance calculate"
      ],
      "metadata": {
        "id": "Vg-ua0eNsIZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for batch in test_dataset:\n",
        "    test_images.append(batch[\"image\"])\n",
        "    test_labels.append(batch[\"label\"])"
      ],
      "metadata": {
        "id": "b8yvreG0lj3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_edit_distance(labels, predictions):\n",
        "    saprse_labels       = tf.sparse.from_dense(labels)\n",
        "    input_len           = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
        "\n",
        "    predictions_decoded = tf.keras.backend.ctc_decode(predictions, input_length=input_len, greedy=False, beam_width=100)[0][0]\n",
        "    sparse_predictions  = tf.sparse.from_dense(predictions_decoded)\n",
        "\n",
        "    edit_distances      = tf.edit_distance(sparse_predictions, saprse_labels, normalize=False)\n",
        "\n",
        "    return tf.reduce_mean(edit_distances)\n",
        "\n",
        "\n",
        "class EditDistanceMetrics:\n",
        "    def __init__(self, prediction_model):\n",
        "        self.prediction_model = prediction_model\n",
        "        self.edit_distances   = []\n",
        "\n",
        "    def evaluate(self, images, labels):\n",
        "        for i in range(len(images)):\n",
        "            label         = labels[i]\n",
        "            prediction    = self.prediction_model.predict(images[i])\n",
        "            edit_distance = calculate_edit_distance(label, prediction).numpy()\n",
        "\n",
        "            self.edit_distances.append(edit_distance)\n",
        "\n",
        "        average_edit_distance = np.mean(self.edit_distances)\n",
        "\n",
        "        return average_edit_distance"
      ],
      "metadata": {
        "id": "iSDJ3bXXlmr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build BatchLossLogger to save loss by step\n"
      ],
      "metadata": {
        "id": "tyHknVeBsL9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchLossLogger(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.batch_losses = []\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        self.batch_losses.append(logs.get(\"loss\"))"
      ],
      "metadata": {
        "id": "CxBMTxT6lyxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train thee model"
      ],
      "metadata": {
        "id": "Qeg8o5ixsaUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs                  = 5\n",
        "\n",
        "early_stopping          = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "\n",
        "batch_loss_logger       = BatchLossLogger()"
      ],
      "metadata": {
        "id": "VpaAiHFtl7li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs, callbacks=[batch_loss_logger, early_stopping])"
      ],
      "metadata": {
        "id": "XA8b2REqmDko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"resnet152_arabic_img2md.h5\")"
      ],
      "metadata": {
        "id": "budHRGFxLrY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the loss plot"
      ],
      "metadata": {
        "id": "3oSEwRUDsd4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure      (figsize=(10, 4))\n",
        "plt.plot        (batch_loss_logger.batch_losses)\n",
        "plt.title       (\"Training Loss per Step (Batch)\")\n",
        "plt.xlabel      (\"Step (Batch)\")\n",
        "plt.ylabel      (\"Loss\")\n",
        "plt.grid        (True)\n",
        "plt.tight_layout()\n",
        "plt.show        ()"
      ],
      "metadata": {
        "id": "LRT-lQaymI77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot  (history.history[\"loss\"]    , label=\"Training Loss\")\n",
        "plt.plot  (history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "\n",
        "plt.title (\"OCR Model Training Progress\", fontsize=14, pad=20)\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss\" , fontsize=12)\n",
        "\n",
        "max_epoch = len(history.history[\"loss\"])\n",
        "\n",
        "plt.xticks      (range(0, max_epoch+1, max(1, max_epoch//10)))\n",
        "plt.grid        (True, linestyle=\"--\", alpha=0.7)\n",
        "plt.legend      (fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show        ()"
      ],
      "metadata": {
        "id": "pBIwz_J7mK7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "QHLG0qiOs-l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_model = keras.models.Model(inputs=model.inputs[0], outputs=model.get_layer(\"dense2\").output)"
      ],
      "metadata": {
        "id": "KCeT8p1_nL5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    input_len   = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results     = ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    output_text = []\n",
        "\n",
        "    for res in results:\n",
        "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res.replace(\"[UNK]\", \"\"))\n",
        "\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "luueF7c2nMjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image      = test_images[0][0]\n",
        "preds      = prediction_model.predict(tf.convert_to_tensor([image]))\n",
        "pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "pred_text  = pred_texts[0]\n",
        "pred_text  = arabic_reshaper.reshape(pred_text)\n",
        "pred_text  = get_display(pred_text)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title (f\"Prediction: {pred_text}\")\n",
        "plt.axis  (\"off\")"
      ],
      "metadata": {
        "id": "7vfqITpf3tDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test_dataset.take(10):\n",
        "    batch_images = batch[\"image\"]\n",
        "    preds        = prediction_model.predict(batch_images)\n",
        "    pred_texts   = decode_batch_predictions(preds)\n",
        "\n",
        "    print(pred_texts)\n",
        "\n",
        "    img       = batch_images[0]\n",
        "    pred_text = pred_texts[0]\n",
        "\n",
        "    if len(img.shape) == 3:\n",
        "        img = (img * 255.0)\n",
        "        img = img[:, :, 0]\n",
        "\n",
        "    elif len(img.shape) == 2: img = (img * 255.0).numpy()\n",
        "\n",
        "    plt.figure      (figsize=(6, 4))\n",
        "    plt.imshow      (img, cmap=\"gray\")\n",
        "    plt.title       (f\"Prediction: {pred_text}\")\n",
        "    plt.axis        (\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show        ()"
      ],
      "metadata": {
        "id": "Lo31ZyujnZa6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}